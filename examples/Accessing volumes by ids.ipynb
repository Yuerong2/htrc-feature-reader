{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import htrc_features\n",
    "import htrc_features.resolvers\n",
    "from htrc_features import Volume, resolvers\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use IDs?\n",
    "\n",
    "In the new version, requesting objects by IDs is the preferred method.\n",
    "\n",
    "There are a few reasons for this.\n",
    "\n",
    "1. Compatability among machines and groups. I've often found it hard to run other people's code because it requires downloading hundreds or thousands of books, when I *already* have a full copy of the Hathi Features on one machine. Different settings will call for different optimizations; workshop users may want to temporarily download files, while HPC environments may want minimally zipped version.\n",
    "\n",
    "2. Alternate storage formats. The new version includes a parquet-based way of referring to files; reading word counts from parquets is much faster than reading from bzipped json files. Referring to IDs makes it easy to silently optimize access to parquet.\n",
    "\n",
    "## What is an ID?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some explanations and tests for the new loading methods.\n",
    "\n",
    "This is not a comprehensive set of tests, but should provide the basics.\n",
    "\n",
    "## Loading from a path.\n",
    "\n",
    "An unnamed initial arg to 'Volume' looks at the format to see if it's an ID or a path. This looks like an ID, so reads from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/hvd.hwrqs8'>Mr. Rutherford's children. By the authors of \"The wide, wide world,\" \"Queechy,\", \"Dollars and cents,\" etc., etc.</a></strong> by <em>Warner, Susan 1819-1885 ,Orr, John William 1815-1887 engr. ,Warner, Anna Bartlett 1824-1915 joint author. </em> (1855, 278 pages) - <code>hvd.hwrqs8</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde848c6710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root = Path(htrc_features.__file__).parent.parent\n",
    "pz_root = Path(project_root, \"data\", \"PZ-volumes\")\n",
    "file_path = Path(pz_root, \"hvd.hwrqs8.json.bz2\").joinpath()\n",
    "file_path = str(file_path)\n",
    "\n",
    "Volume(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfile.tempdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading over the web\n",
    "\n",
    "This one loads from the web. There are probably more gentle defaults than re-pulling from online every time, and these should be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/hvd.hwrqs8'>Mr. Rutherford's children. By the authors of \"The wide, wide world,\" \"Queechy,\", \"Dollars and cents,\" etc., etc.</a></strong> by <em>Warner, Susan 1819-1885 ,Orr, John William 1815-1887 engr. ,Warner, Anna Bartlett 1824-1915 joint author. </em> (1855, 278 pages) - <code>hvd.hwrqs8</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde83b69b70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Volume(\"hvd.hwrqs8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing files by volume ids.\n",
    "\n",
    "That's basically the entire old method. But you may want to access local objects by their HTIDs. The simplest way to \n",
    "do that is to use the 'local' resolver, which looks in a named directory for an appropriate file. Since the default arguments are 'json' storage with 'bz2' compression, this works with three arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">body</th>\n",
       "      <th>1C</th>\n",
       "      <th>CC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">body</th>\n",
       "      <th>.</th>\n",
       "      <th>$.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>NE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR</th>\n",
       "      <th>NE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count\n",
       "page section token    pos       \n",
       "2    body    1C       CC       1\n",
       "             i        NN       1\n",
       "7    body    .        $.       1\n",
       "             CHILDREN NE       1\n",
       "             MR       NE       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = Volume(id = \"hvd.hwrqs8\", dir = os.path.join(pz_root), id_resolver = \"local\")\n",
    "vol.tokenlist().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing arguments to resolver directly.\n",
    "\n",
    "Ordinary users will generally only interact with these classes through arguments to the Volume method. But we can also call 'LocalResolver' directly.\n",
    "\n",
    "In this example, we can use instead 'localResolver'. We say we're using json, bz2, and a folder named `../data/PZ-volumes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/hvd.hwrqs8'>Mr. Rutherford's children. By the authors of \"The wide, wide world,\" \"Queechy,\", \"Dollars and cents,\" etc., etc.</a></strong> by <em>Warner, Susan 1819-1885 ,Orr, John William 1815-1887 engr. ,Warner, Anna Bartlett 1824-1915 joint author. </em> (1855, 278 pages) - <code>hvd.hwrqs8</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde81a87b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileholder = resolvers.LocalResolver(dir = pz_root, format = \"json\", compression = \"bz2\")\n",
    "\n",
    "locally_resolved_file = Volume(id = \"hvd.hwrqs8\", id_resolver = fileholder, format = \"json\")\n",
    "\n",
    "locally_resolved_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOT IMPLEMENTED: lambda resolution\\n\\nsimple_handler = lambda x: open(\"../data/PZ-volumes/\" + x + \".json.bz2\", mode = \"r\")\\n\\nlocally_resolved_file = Volume(id = \"hvd.hwrqs8\", id_resolver = simple_handler, format = \"json\")\\n\\nlocally_resolved_file\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOT IMPLEMENTED: lambda resolution\n",
    "\n",
    "simple_handler = lambda x: open(\"../data/PZ-volumes/\" + x + \".json.bz2\", mode = \"r\")\n",
    "\n",
    "locally_resolved_file = Volume(id = \"hvd.hwrqs8\", id_resolver = simple_handler, format = \"json\")\n",
    "\n",
    "locally_resolved_file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing arguments to resolver and handler directly.\n",
    "\n",
    "While HTTP fetching is currently silent, we should probably warn when that happens without an explicit request. Here's how you'd do that. Here I invoke the JsonFileHandler directly, rather than wrapping it in volume; it's unlikely an end user will ever need to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">body</th>\n",
       "      <th>1C</th>\n",
       "      <th>CC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">body</th>\n",
       "      <th>.</th>\n",
       "      <th>$.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>NE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR</th>\n",
       "      <th>NE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count\n",
       "page section token    pos       \n",
       "2    body    1C       CC       1\n",
       "             i        NN       1\n",
       "7    body    .        $.       1\n",
       "             CHILDREN NE       1\n",
       "             MR       NE       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webresolver = htrc_features.resolvers.HttpResolver(url = 'http://data.htrc.illinois.edu/htrc-ef-access/get?action=download-ids&id={id}&output=json')\n",
    "\n",
    "remote_handler = htrc_features.JsonFileHandler(id = \"hvd.hwrqs8\", id_resolver = webresolver)\n",
    "\n",
    "remote_handler._make_tokencount_df().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fancy zip storage\n",
    "\n",
    "When working with millions of files, some systems start to run out of inodes. Here, we build a storage using the 'ziptreeresolver' method, which assigns each file to one of 4096 zip files based on its name. Here, I'll create one in a tmpdir first. This, as a file writing operation, is a little more complicated than the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = tempfile.TemporaryDirectory()\n",
    "zipdir = sample_dir.name\n",
    "\n",
    "zipholder = resolvers.ZiptreeResolver(zipdir, format = \"json\", compression = \"bz2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll go through the PZ-volumes folder and, for every volume, \n",
    "\n",
    "1. Grab the ID.\n",
    "2. Read the bzipped binary data into memory\n",
    "3. Reinsert that binary data into the ziptree holder.\n",
    "\n",
    "Note that we tell the zipholder to use 'json' storage' and 'bz2' compression. Note that this insertion roundtrip actually decompresses and recompresses the data because of the way that the `IdHandler.open` method works: there are faster ways to insert the binary data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm /tmp/*.zip\n",
    "\n",
    "\n",
    "ids = set()\n",
    "\n",
    "current_resolver = htrc_features.resolvers.LocalResolver(pz_root, format = \"json\", compression = \"bz2\")\n",
    "\n",
    "for file in os.listdir(pz_root):\n",
    "    if file.endswith(\".bz2\"):\n",
    "        id = htrc_features.utils.extract_htid(file)\n",
    "        with current_resolver.open(id, format = \"json\", compression = \"bz2\") as original:\n",
    "            d = original.read()\n",
    "            try:\n",
    "                with zipholder.open(id, format = \"json\", compression = \"bz2\", mode = \"wb\") as fout:\n",
    "                    fout.write(d)\n",
    "            except KeyError:\n",
    "                print(\"Already inserted {id}\".format(id=id))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new tmpdir is filled with zipfiles. There are 4096 names, built from the first three characters of sha-1 hashes of the filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e99.zip',\n",
       " 'd33.zip',\n",
       " '7d2.zip',\n",
       " '173.zip',\n",
       " 'e6f.zip',\n",
       " 'e14.zip',\n",
       " '553.zip',\n",
       " 'c5f.zip',\n",
       " 'e6b.zip',\n",
       " '96c.zip',\n",
       " 'a97.zip',\n",
       " '613.zip',\n",
       " '915.zip',\n",
       " '940.zip',\n",
       " 'b75.zip']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[z for z in os.listdir(zipdir) if z.endswith(\".zip\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipdir reading\n",
    "\n",
    "Now we can extract any individual file from these zipdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/hvd.32044010273894'>The ballet dancer, and On guard,</a></strong> by <em>Serao, Matilde. </em> (1901, 284 pages) - <code>hvd.32044010273894</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde805f7860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Volume(\"hvd.32044010273894\", format = \"json\", compression = \"bz2\", id_resolver = \"ziptree\", dir = zipdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features.caching import copy_between_resolvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to copy from these to some other form of resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"id\":\"hvd.32044010273894\",\"metadata\":{\"schemaVersion\":\"1.3\",\"dateCreated\":\"2016-06-18T21:16:55.4637562Z\",\"volumeIdentifier\":\"hvd.32044010273894\",\"accessProfile\":\"google\",\"rightsAttributes\":\"pd\",\"hathitrustRecordNumber\":\"1219987\",\"enumerationChronology\":\" \",\"sourceInstitution\":\"HVD\",\"sourceInstituti'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairtree_resolver = resolvers.PairtreeResolver(dir = tempfile.gettempdir(), format = \"json\", compression = \"bz2\")\n",
    "copy_between_resolvers(\"hvd.32044010273894\", resolvers.ZiptreeResolver(dir = zipdir, compression = \"bz2\", format=\"json\"), pairtree_resolver)\n",
    "\n",
    "pairtree_resolver.open(id = \"hvd.32044010273894\").read()[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving Parquet\n",
    "\n",
    "Parquet caches can be resolved in exactly the same way. The defaults may break more easily, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/mdp.39015028036104'>Russian short stories, ed. for school use,</a></strong> by <em>Schweikert, Harry Christian 1877- ed. </em> (1919, 460 pages) - <code>mdp.39015028036104</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde80723438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = Volume(id = \"mdp.39015028036104\", dir = Path(project_root, \"data/parquet\"), format = \"parquet\", id_resolver = \"local\")\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferring between formats\n",
    "\n",
    "To transfer files between formats, you simply need two resolvers. The following code shows how to do do this.\n",
    "\n",
    "This code is smart enough to know that if you are copying from one bz2 file to another, it need not decompress and recompress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_between_resolvers(id, resolver1, resolver2):\n",
    "    input = Volume(id, id_resolver=resolver1)\n",
    "    output = Volume(id, id_resolver=resolver2, mode = 'wb')\n",
    "    output.write(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 resolvers\n",
    "\n",
    "Here's a sort of silly example that's part of the test suite. It's easy to transition between a variety of different implementations.\n",
    "\n",
    "This simply read and copy method will be the basis of methods that allow fallback searches and automatic caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as first_new_dir:\n",
    "    with tempfile.TemporaryDirectory() as second_new_dir:\n",
    "        resolver1 = htrc_features.resolvers.LocalResolver(dir = Path(project_root, \"tests\", \"data\"), format = \"json\", compression = \"bz2\")\n",
    "        resolver2 = htrc_features.resolvers.PairtreeResolver(dir = first_new_dir,  format = \"json\", compression = \"gz\")\n",
    "        resolver3 = htrc_features.resolvers.LocalResolver(dir = second_new_dir, format = \"parquet\", compression = \"snappy\")\n",
    "        \n",
    "        copy_between_resolvers(\"aeu.ark:/13960/t1rf63t52\", resolver1, resolver2)\n",
    "        copy_between_resolvers(\"aeu.ark:/13960/t1rf63t52\", resolver2, resolver3)\n",
    "        \n",
    "        all_files = []\n",
    "        for loc, dir, files in os.walk(first_new_dir):\n",
    "            for file in files:\n",
    "                all_files.append(os.path.join(loc, file))\n",
    "                \n",
    "        assert(len(all_files) == 1)\n",
    "        assert(all_files[0].endswith(\"aeu/pairtree_root/ar/k+/=1/39/60/=t/1r/f6/3t/52/ark+=13960=t1rf63t52/aeu.ark+=13960=t1rf63t52.json.gz\"))\n",
    "        \n",
    "        # Our test assertion ensures that the data has made it all the way through.\n",
    "        assert(Volume(\"aeu.ark:/13960/t1rf63t52\", id_resolver = resolver3).tokenlist()['count'].sum() == 97691)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache resolvers\n",
    "\n",
    "This logic is extended in the core library to the methods for 'cache_local', 'cache_pairtree', and 'cache_ziptree' that first look locally and then on the internet. These are implemented using a function, make_cache_resolver, that returns a new class constructor. We can make our own between any two resolvers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.gettempdir()\n",
    "from htrc_features import caching\n",
    "CacheResolver = caching.make_fallback_resolver(resolvers.PairtreeResolver, resolvers.HttpResolver(), cache = True)\n",
    "my_resolver = CacheResolver(dir = os.path.join(tmpdir, \"new_resolution\"), format = \"json\", compression = \"gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<htrc_features.resolvers.HttpResolver at 0x7fde80722d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolvers.HttpResolver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of this resolver is pretty ugly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "htrc_features.caching.make_fallback_resolver.<locals>.FallbackResolver"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(my_resolver, resolvers.IdResolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But its behavior is great. You can now download automatically from Hathi. The first occasion takes a while--9 seconds--to pull from the Internet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 316 ms, sys: 24 ms, total: 340 ms\n",
      "Wall time: 340 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/mdp.39015051692625'>Marāṭhī nāṭyakośa : nāṭaka-raṅgabhūmīvishayaka nivaḍaka māhitī deṇārā grantha / sampādana, Vi. Bhā. Deśapāṇḍe.</a></strong> by <em>Deśapāṇḍe, Vi. Bhā. (Viśvanātha Bhālacandra) 1938- </em> (2000, 1394 pages) - <code>mdp.39015051692625</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde80722be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Volume(id = \"mdp.39015051692625\", id_resolver = my_resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the next one is quick! Just 500 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 252 ms, sys: 12 ms, total: 264 ms\n",
      "Wall time: 260 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/mdp.39015051692625'>Marāṭhī nāṭyakośa : nāṭaka-raṅgabhūmīvishayaka nivaḍaka māhitī deṇārā grantha / sampādana, Vi. Bhā. Deśapāṇḍe.</a></strong> by <em>Deśapāṇḍe, Vi. Bhā. (Viśvanātha Bhālacandra) 1938- </em> (2000, 1394 pages) - <code>mdp.39015051692625</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x7fde80721278>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Volume(id = \"mdp.39015051692625\", id_resolver = my_resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Id 'mdp.39015051692625' already in zipfile. Refusing to overwrite\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Empty buffer found very late",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2f4c587f749a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_ziptree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZiptreeResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"new_ziptree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcopy_between_resolvers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mdp.39015051692625\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_resolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ziptree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#copy_between_resolvers(\"mdp.39015051692625\", resolvers.HttpResolver(), zipholder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-969b3ca739ec>\u001b[0m in \u001b[0;36mcopy_between_resolvers\u001b[0;34m(id, resolver1, resolver2)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_resolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolver1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_resolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolver2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/lib/python/htrc-feature-reader/htrc_features/feature_reader.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, volume, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/lib/python/htrc-feature-reader/htrc_features/parsers.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, outside_volume, compression, mode, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         with self.resolver.open(self.id, compression = self.compression, format = 'json',\n\u001b[1;32m    193\u001b[0m                                 \u001b[0mskip_compression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskip_compression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                                 **kwargs) as fout:\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_bytestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/lib/python/htrc-feature-reader/htrc_features/resolvers.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, id, suffix, format, mode, skip_compression, compression, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muncompressed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty buffer found very late\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# The name here is misleading; if mode is 'w', 'decompress' may actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Empty buffer found very late"
     ]
    }
   ],
   "source": [
    "new_ziptree = resolvers.ZiptreeResolver(dir = os.path.join(tmpdir, \"new_ziptree\"), format='json', mode='w')\n",
    "copy_between_resolvers(\"mdp.39015051692625\", my_resolver, new_ziptree)\n",
    "#copy_between_resolvers(\"mdp.39015051692625\", resolvers.HttpResolver(), zipholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ziptree.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_vol = Volume(id = \"mdp.39015051692625\", id_resolver = new_ziptree, format = \"parquet\")\n",
    "\n",
    "parquet_vol.tokenlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = new_ziptree.open(\"mdp.39015051692625\", mode = 'rb', suffix = 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume(id = \"mdp.39015051692625\", id_resolver = \"pairtree_cache\", dir = os.path.join(tmpdir, \"new_pairtree\"), format = \"parquet\").tokenlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(project_root, \"tests\", \"data\").iterdir().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume(Path(project_root, 'tests/data/green-gables-15pages.json').__str__(), compression = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver2 = htrc_features.resolvers.IdResolver(dir = \".\", format = \"parquet\", compression = \"snappy\")\n",
    "\n",
    "# Don't use compression in the name\n",
    "testname = resolver2.fname(\"mdp.12345\", format = \"parquet\", compression = \"snappy\", suffix = \"tokens\")\n",
    "assert(testname == \"mdp.12345.tokens.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (htrc)",
   "language": "python",
   "name": "htrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
